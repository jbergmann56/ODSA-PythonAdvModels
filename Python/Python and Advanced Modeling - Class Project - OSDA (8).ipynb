{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Purpose: Class Project that covers the material learned in the \"Python & Advanced Modeling\" class, \n",
    "#Following CRISP-DM methodology for data science projects:  1) Business Understanding, 2) Data Understanding/Preparation,\n",
    "#3) Model Building & Evaluation,  4) Deployment \n",
    "import requests  #GET/POST/PUT API requests\n",
    "from contextlib import closing  #utilities for common tasks involving the \"with\" statement.\n",
    "from bs4 import BeautifulSoup #BeautifulSoup4 - HTML Web Scraping #Scrapy\n",
    "import csv #write stock information to csv file\n",
    "import json #create json payload and/or parse json response set from API\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import * #random number generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CRISP-DM Step 2a) Obtain Data - Use your favorite Pandas library to \"wrangle\" your data for analysis!\n",
    "#API Get Request\n",
    "def API_get(view_url):\n",
    "    #set url for json request, then obtain json response/payload\n",
    "    #ex: view_url = 'https://jsonplaceholder.typicode.com/todos'\n",
    "    myResponse = requests.get(view_url)\n",
    "    #print (myResponse.status_code)\n",
    "    # For successful API call, response code will be 200 (OK)\n",
    "    if(myResponse.ok):\n",
    "        # Loads (Load String) takes a Json file and converts into python data structure \n",
    "        # (dict or list, depending on JSON structure and number of records returned\n",
    "        jData = myResponse.content \n",
    "        # Loading the response data into a dict variable\n",
    "        jData = json.loads(jData) \n",
    "        print(\"The API Get Request Was Successful\")\n",
    "        print(\"\\n\")\n",
    "        return jData\n",
    "        \n",
    "    else:\n",
    "        # If response code is not ok (200), print the resulting http error code with description\n",
    "        print('API Error')\n",
    "        return ''\n",
    "    \n",
    "#Web Scrape experimentation - https://realpython.com/blog/\n",
    "def screen_scrape(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(requests.get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                print('http request successful')\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        print('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "#Create functions to Read/Write CSV & Excel Data using Pandas \n",
    "def file_read_csv(path):\n",
    "    print(\"Pandas File I/O Example - CSV Read\")\n",
    "    #load csv file into Pandas dataframe object\n",
    "    data=pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def file_read_excel(path,sheet):\n",
    "    print(\"Pandas File I/O Example - Excel Read\")\n",
    "    #load csv file into Pandas dataframe object\n",
    "    xlsx = pd.ExcelFile(path)\n",
    "    data = pd.read_excel(xlsx, sheet)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API Get Request Was Successful\n",
      "\n",
      "\n",
      "Check Response - Print the title of the 10th entry in returned dictionary: vero rerum temporibus dolor\n",
      "  completed  id                                              title  userId\n",
      "0     False   1                                 delectus aut autem       1\n",
      "1     False   2                 quis ut nam facilis et officia qui       1\n",
      "2     False   3                                fugiat veniam minus       1\n",
      "3      True   4                                   et porro tempora       1\n",
      "4     False   5  laboriosam mollitia et enim quasi adipisci qui...       1\n",
      "Row axis labels and column axis labels are:\n",
      "[RangeIndex(start=0, stop=200, step=1), Index(['completed', 'id', 'title', 'userId'], dtype='object')]\n",
      "The data types of each column are:\n",
      "completed      bool\n",
      "id            int64\n",
      "title        object\n",
      "userId        int64\n",
      "dtype: object\n",
      "The shape of the object is: r x c\n",
      "(200, 4)\n",
      "               id      userId\n",
      "count  200.000000  200.000000\n",
      "mean   100.500000    5.500000\n",
      "std     57.879185    2.879489\n",
      "min      1.000000    1.000000\n",
      "25%     50.750000    3.000000\n",
      "50%    100.500000    5.500000\n",
      "75%    150.250000    8.000000\n",
      "max    200.000000   10.000000\n"
     ]
    }
   ],
   "source": [
    "#CRISP-DM Step 2b & 2c - transform data to place in Pandas dataset (Step 2a), \n",
    "#for further understanding and model prep/usage (Step 2b)\n",
    "#\"get\" data from API endpoint \n",
    "data = API_get('https://jsonplaceholder.typicode.com/todos')\n",
    "print(\"Check Response - Print the title of the 10th entry in returned dictionary: {}\".format(data[10]['title']))\n",
    "\n",
    "#place python dictionary in pandas dataframe  \n",
    "data_API = pd.DataFrame(data)\n",
    "print(data_API.head())\n",
    "\n",
    "#Step 2c - Evaluate API data for furter text (or other) analysis\n",
    "print (\"Row axis labels and column axis labels are:\")\n",
    "print(data_API.axes)\n",
    "print (\"The data types of each column are:\")\n",
    "print(data_API.dtypes)\n",
    "print (\"The shape of the object is: r x c\")\n",
    "print(data_API.shape)\n",
    "print(data_API.describe())  #numerically describe columns in dataset\n",
    "\n",
    "#Visually Graph & discover in another tool such as tableau - export transformed/cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http request successful\n",
      "range(0, 100)\n",
      "                  0             1             2             3             4   \\\n",
      "close         170.18        170.89        169.43        170.41        170.94   \n",
      "date    Feb 13, 2019  Feb 12, 2019  Feb 11, 2019  Feb 08, 2019  Feb 08, 2019   \n",
      "open          171.39        170.10        171.05        168.99        172.40   \n",
      "volume    22,479,799    22,229,900    20,993,400    23,820,000    31,741,700   \n",
      "\n",
      "                  5             6             7             8             9   \\\n",
      "close         174.24        174.18        171.25        166.52        166.44   \n",
      "date    Feb 07, 2019  Feb 06, 2019  Feb 05, 2019  Feb 04, 2019  Feb 01, 2019   \n",
      "open          174.65        172.86        167.41        166.96        166.11   \n",
      "volume    28,239,600    36,101,600    31,495,500    32,668,100    40,739,600   \n",
      "\n",
      "            ...                 88            89            90            91  \\\n",
      "close       ...             224.29        227.99        232.07        229.28   \n",
      "date        ...       Oct 09, 2018  Oct 08, 2018  Oct 05, 2018  Oct 04, 2018   \n",
      "open        ...             227.96        230.78        230.05        227.25   \n",
      "volume      ...         33,580,500    32,042,000    28,654,800    24,788,200   \n",
      "\n",
      "                  92            93            94            95            96  \\\n",
      "close         227.26        225.74        224.95        220.42        222.19   \n",
      "date    Oct 03, 2018  Oct 02, 2018  Oct 01, 2018  Sep 28, 2018  Sep 27, 2018   \n",
      "open          227.95        224.79        223.82        221.00        219.75   \n",
      "volume    23,600,800    22,929,400    30,181,200    23,984,700    24,554,400   \n",
      "\n",
      "                  97  \n",
      "close         220.79  \n",
      "date    Sep 26, 2018  \n",
      "open          216.82  \n",
      "volume    27,693,400  \n",
      "\n",
      "[4 rows x 98 columns]\n",
      "    close          date    open      volume\n",
      "0  170.18  Feb 13, 2019  171.39  22,479,799\n",
      "1  170.89  Feb 12, 2019  170.10  22,229,900\n",
      "2  169.43  Feb 11, 2019  171.05  20,993,400\n",
      "3  170.41  Feb 08, 2019  168.99  23,820,000\n",
      "4  170.94  Feb 08, 2019  172.40  31,741,700\n",
      "0     Feb 13, 2019\n",
      "1     Feb 12, 2019\n",
      "2     Feb 11, 2019\n",
      "3     Feb 08, 2019\n",
      "4     Feb 08, 2019\n",
      "5     Feb 07, 2019\n",
      "6     Feb 06, 2019\n",
      "7     Feb 05, 2019\n",
      "8     Feb 04, 2019\n",
      "9     Feb 01, 2019\n",
      "10    Jan 31, 2019\n",
      "11    Jan 30, 2019\n",
      "12    Jan 29, 2019\n",
      "13    Jan 28, 2019\n",
      "14    Jan 25, 2019\n",
      "15    Jan 24, 2019\n",
      "16    Jan 23, 2019\n",
      "17    Jan 22, 2019\n",
      "18    Jan 18, 2019\n",
      "19    Jan 17, 2019\n",
      "20    Jan 16, 2019\n",
      "21    Jan 15, 2019\n",
      "22    Jan 14, 2019\n",
      "23    Jan 11, 2019\n",
      "24    Jan 10, 2019\n",
      "25    Jan 09, 2019\n",
      "26    Jan 08, 2019\n",
      "27    Jan 07, 2019\n",
      "28    Jan 04, 2019\n",
      "29    Jan 03, 2019\n",
      "          ...     \n",
      "68    Nov 06, 2018\n",
      "69    Nov 05, 2018\n",
      "70    Nov 02, 2018\n",
      "71    Nov 01, 2018\n",
      "72    Oct 31, 2018\n",
      "73    Oct 30, 2018\n",
      "74    Oct 29, 2018\n",
      "75    Oct 26, 2018\n",
      "76    Oct 25, 2018\n",
      "77    Oct 24, 2018\n",
      "78    Oct 23, 2018\n",
      "79    Oct 22, 2018\n",
      "80    Oct 19, 2018\n",
      "81    Oct 18, 2018\n",
      "82    Oct 17, 2018\n",
      "83    Oct 16, 2018\n",
      "84    Oct 15, 2018\n",
      "85    Oct 12, 2018\n",
      "86    Oct 11, 2018\n",
      "87    Oct 10, 2018\n",
      "88    Oct 09, 2018\n",
      "89    Oct 08, 2018\n",
      "90    Oct 05, 2018\n",
      "91    Oct 04, 2018\n",
      "92    Oct 03, 2018\n",
      "93    Oct 02, 2018\n",
      "94    Oct 01, 2018\n",
      "95    Sep 28, 2018\n",
      "96    Sep 27, 2018\n",
      "97    Sep 26, 2018\n",
      "Name: date, dtype: object\n",
      "Row axis labels and column axis labels are:\n",
      "[Index(['close', 'date', 'open', 'volume'], dtype='object'), Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "            68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "            85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97],\n",
      "           dtype='int64')]\n",
      "The data types of each column are:\n",
      "0     object\n",
      "1     object\n",
      "2     object\n",
      "3     object\n",
      "4     object\n",
      "5     object\n",
      "6     object\n",
      "7     object\n",
      "8     object\n",
      "9     object\n",
      "10    object\n",
      "11    object\n",
      "12    object\n",
      "13    object\n",
      "14    object\n",
      "15    object\n",
      "16    object\n",
      "17    object\n",
      "18    object\n",
      "19    object\n",
      "20    object\n",
      "21    object\n",
      "22    object\n",
      "23    object\n",
      "24    object\n",
      "25    object\n",
      "26    object\n",
      "27    object\n",
      "28    object\n",
      "29    object\n",
      "       ...  \n",
      "68    object\n",
      "69    object\n",
      "70    object\n",
      "71    object\n",
      "72    object\n",
      "73    object\n",
      "74    object\n",
      "75    object\n",
      "76    object\n",
      "77    object\n",
      "78    object\n",
      "79    object\n",
      "80    object\n",
      "81    object\n",
      "82    object\n",
      "83    object\n",
      "84    object\n",
      "85    object\n",
      "86    object\n",
      "87    object\n",
      "88    object\n",
      "89    object\n",
      "90    object\n",
      "91    object\n",
      "92    object\n",
      "93    object\n",
      "94    object\n",
      "95    object\n",
      "96    object\n",
      "97    object\n",
      "dtype: object\n",
      "The shape of the object is: r x c\n",
      "(4, 98)\n",
      "                0       1           2       3       4       5           6   \\\n",
      "count            4       4           4       4       4       4           4   \n",
      "unique           4       4           4       4       4       4           4   \n",
      "top     22,479,799  170.10  20,993,400  168.99  172.40  174.65  36,101,600   \n",
      "freq             1       1           1       1       1       1           1   \n",
      "\n",
      "            7       8           9    ...        88          89      90  \\\n",
      "count        4       4           4   ...         4           4       4   \n",
      "unique       4       4           4   ...         4           4       4   \n",
      "top     167.41  166.96  40,739,600   ...    227.96  32,042,000  232.07   \n",
      "freq         1       1           1   ...         1           1       1   \n",
      "\n",
      "                  91          92      93            94      95            96  \\\n",
      "count              4           4       4             4       4             4   \n",
      "unique             4           4       4             4       4             4   \n",
      "top     Oct 04, 2018  23,600,800  225.74  Oct 01, 2018  221.00  Sep 27, 2018   \n",
      "freq               1           1       1             1       1             1   \n",
      "\n",
      "            97  \n",
      "count        4  \n",
      "unique       4  \n",
      "top     216.82  \n",
      "freq         1  \n",
      "\n",
      "[4 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "#CRISP-DM Step 2b & 2c - transform data to place in Pandas dataset (Step 2a), \n",
    "#for further understanding and model prep/usage (Step 2b)\n",
    "#Web Scrape experimentation - https://realpython.com/python-web-scraping-practical-introduction/\n",
    "raw_html = screen_scrape('https://finance.yahoo.com/quote/AAPL/history?p=AAPL')\n",
    "#using BeautifulSoap to parse html elements and scrape web page\n",
    "html = BeautifulSoup(raw_html, 'html.parser')\n",
    "# Take out the <div> of name and get the stock's value\n",
    "stock_date = html.findAll(\"td\", attrs={\"class\": \"Py(10px) Ta(start) Pend(10px)\"})\n",
    "\n",
    "#iterate through elements to get stock dates\n",
    "stock_date = []\n",
    "for i, text in enumerate(html.findAll(\"td\", attrs={\"class\": \"Py(10px) Ta(start) Pend(10px)\"})):\n",
    "    stock_date.insert(i,text.span.string)\n",
    "#print(stock_date)\n",
    "\n",
    "#create list to store other stock data\n",
    "stock_data = []\n",
    "for i, text in enumerate(html.findAll(\"td\", attrs={\"class\": \"Py(10px) Pstart(10px)\"})):\n",
    "    stock_data.insert(i,text.span.string)\n",
    "#print(stock_data)\n",
    "\n",
    "#combine date and stock information into dictionary data structure\n",
    "i = 0\n",
    "stock_info = {}\n",
    "print(range(len(stock_date)))\n",
    "for i in range(len(stock_date)-2):  #get stock info for every day\n",
    "    stock_info[i] = {\"date\": stock_date[i], \"open\": stock_data[(i*6)+0], \"close\": stock_data[(i*6)+3], \"volume\": stock_data[(i*6)+5]}\n",
    "    #print(stock_info[i])\n",
    "    \n",
    "#place python dictionary in pandas dataframe\n",
    "data_scrape = pd.DataFrame(stock_info)\n",
    "print(data_scrape.head())  #probably not the row x column format we want!\n",
    "data_scrape2 = data_scrape.T #transpose dataset to get column names \"on top\" of dataframe\n",
    "print(data_scrape2.head())\n",
    "print(data_scrape2.date) #get all dates in dataset\n",
    "\n",
    "#Step 2c - Evaluate scraped data for furter text (or other) analysis\n",
    "print (\"Row axis labels and column axis labels are:\")\n",
    "print(data_scrape.axes)\n",
    "print (\"The data types of each column are:\")\n",
    "print(data_scrape.dtypes)\n",
    "print (\"The shape of the object is: r x c\")\n",
    "print(data_scrape.shape)\n",
    "print(data_scrape.describe())  #numerically describe columns in dataset\n",
    "\n",
    "#Visually Graph & discover in another tool such as tableau - export transformed/cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas File I/O Example - Excel Read\n",
      "        Date     Open     High      Low    Close      Volume  Adj Close  \\\n",
      "0 2009-04-23  7886.81  8015.36  7762.80  7957.06  6563100000    7957.06   \n",
      "1 2009-04-22  7964.78  8111.02  7802.46  7886.57  7327860000    7886.57   \n",
      "2 2009-04-21  7841.73  8027.54  7699.79  7969.56  7436489600    7969.56   \n",
      "3 2009-04-20  8128.94  8128.94  7801.58  7841.73  6973960000    7841.73   \n",
      "4 2009-04-17  8125.43  8251.20  8024.92  8131.33  7352009600    8131.33   \n",
      "\n",
      "  Symbol  log2_open  d1_cls_chg  d5_cls_chg  d10_cls_chg  d30_cls_chg  \\\n",
      "0    DJI   3.896901       70.49     -168.37       119.95      1026.66   \n",
      "1    DJI   3.901174      -82.99     -143.05        97.01       960.08   \n",
      "2    DJI   3.894412      127.83       49.38        -6.29      1422.51   \n",
      "3    DJI   3.910034     -289.60     -216.08      -175.86      1214.79   \n",
      "4    DJI   3.909846        5.90       47.95       153.25      1536.89   \n",
      "\n",
      "    d1_vol_chg  d5_cls_chg.1  d10_cls_chg.1  d30_cls_chg.1  d1_cls_pcnt_chg  \\\n",
      "0 -764760000.0 -3.557000e+07   6.246400e+08  -7.247096e+08         0.008938   \n",
      "1 -108629600.0  1.086760e+09   2.172280e+09  -1.290470e+09        -0.010413   \n",
      "2  462529600.0 -1.333504e+08   1.226490e+09   1.591696e+08         0.016301   \n",
      "3 -378049600.0  5.390700e+08   1.118320e+09  -3.578704e+08        -0.035615   \n",
      "4  753339600.0 -2.487008e+08  -1.908000e+08  -1.552400e+08         0.000726   \n",
      "\n",
      "     mavg_200d  \n",
      "0  8208.709348  \n",
      "1  8225.871087  \n",
      "2  8244.684710  \n",
      "3  8265.420290  \n",
      "4  8287.224130  \n",
      "Row axis labels and column axis labels are:\n",
      "[RangeIndex(start=0, stop=1258, step=1), Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'Symbol',\n",
      "       'log2_open', 'd1_cls_chg', 'd5_cls_chg', 'd10_cls_chg', 'd30_cls_chg',\n",
      "       'd1_vol_chg', 'd5_cls_chg.1', 'd10_cls_chg.1', 'd30_cls_chg.1',\n",
      "       'd1_cls_pcnt_chg', 'mavg_200d'],\n",
      "      dtype='object')]\n",
      "The data types of each column are:\n",
      "Date               datetime64[ns]\n",
      "Open                      float64\n",
      "High                      float64\n",
      "Low                       float64\n",
      "Close                     float64\n",
      "Volume                      int64\n",
      "Adj Close                 float64\n",
      "Symbol                     object\n",
      "log2_open                 float64\n",
      "d1_cls_chg                float64\n",
      "d5_cls_chg                float64\n",
      "d10_cls_chg               float64\n",
      "d30_cls_chg               float64\n",
      "d1_vol_chg                float64\n",
      "d5_cls_chg.1              float64\n",
      "d10_cls_chg.1             float64\n",
      "d30_cls_chg.1             float64\n",
      "d1_cls_pcnt_chg           float64\n",
      "mavg_200d                 float64\n",
      "dtype: object\n",
      "The shape of the object is: r x c\n",
      "(1258, 19)\n",
      "               Open          High           Low         Close        Volume  \\\n",
      "count   1258.000000   1258.000000   1258.000000   1258.000000  1.258000e+03   \n",
      "mean   11175.665397  11289.744070  11060.217091  11174.502409  3.108896e+09   \n",
      "std     1523.082171   1517.291667   1532.142445   1525.481117  1.720855e+09   \n",
      "min     6547.010000   6758.440000   6440.080000   6547.050000  2.200000e+06   \n",
      "25%    10385.600000  10471.995000  10314.045000  10385.702500  1.878948e+09   \n",
      "50%    11015.280000  11115.400000  10907.485000  11015.440000  2.570620e+09   \n",
      "75%    12379.742500  12515.060000  12261.052500  12378.202500  3.893618e+09   \n",
      "max    14165.020000  14279.960000  13980.900000  14164.530000  1.145623e+10   \n",
      "\n",
      "          Adj Close    log2_open   d1_cls_chg   d5_cls_chg  d10_cls_chg  \\\n",
      "count   1258.000000  1258.000000  1257.000000  1253.000000  1248.000000   \n",
      "mean   11174.502409     4.043975    -1.979053    -9.558723   -18.478694   \n",
      "std     1525.481117     0.062305   134.872248   259.930298   350.028306   \n",
      "min     6547.050000     3.816043  -777.680000 -1903.660000 -2691.940000   \n",
      "25%    10385.702500     4.016432   -55.970000  -125.310000  -178.787500   \n",
      "50%    11015.440000     4.041996     4.560000    18.990000    36.880000   \n",
      "75%    12378.202500     4.092712    57.810000   139.830000   187.892500   \n",
      "max    14164.530000     4.151217   936.420000  1276.750000  1228.810000   \n",
      "\n",
      "       d30_cls_chg    d1_vol_chg  d5_cls_chg.1  d10_cls_chg.1  d30_cls_chg.1  \\\n",
      "count  1228.000000  1.257000e+03  1.253000e+03   1.248000e+03   1.228000e+03   \n",
      "mean    -58.780440  4.194511e+06  2.194375e+07   4.332943e+07   1.335486e+08   \n",
      "std     615.825337  6.560018e+08  8.738325e+08   9.941469e+08   1.115722e+09   \n",
      "min   -3263.990000 -4.506390e+09 -6.352880e+09  -5.108260e+09  -5.243640e+09   \n",
      "25%    -315.682500 -1.963500e+08 -2.400500e+08  -2.747700e+08  -2.898550e+08   \n",
      "50%      61.095000  6.110000e+06  9.340000e+06   1.434020e+07   9.596000e+07   \n",
      "75%     309.345000  2.250000e+08  2.918200e+08   3.656525e+08   4.765725e+08   \n",
      "max    1536.890000  4.941390e+09  4.740110e+09   6.072620e+09   8.212560e+09   \n",
      "\n",
      "       d1_cls_pcnt_chg     mavg_200d  \n",
      "count      1257.000000   1120.000000  \n",
      "mean         -0.000125  11435.428505  \n",
      "std           0.013566   1225.060096  \n",
      "min          -0.078733   8208.709348  \n",
      "25%          -0.005011  10510.946612  \n",
      "50%           0.000408  11146.935036  \n",
      "75%           0.005159  12537.950380  \n",
      "max           0.110803  13532.582246  \n"
     ]
    }
   ],
   "source": [
    "#CRISP-DM Step 2b & 2c - transform data to place in Pandas dataset (Step 2a), \n",
    "#for further understanding and model prep/usage (Step 2b)\n",
    "#Pandas CSV Example\n",
    "data_xls = file_read_excel('C:\\\\Python\\\\Data\\\\indicator_stock_hist.xls','^DJI') #older version of excel - can use new .xlsx\n",
    "print(data_xls.head())\n",
    "\n",
    "#Step 2c - Evaluate excel data for furter text (or other) analysis\n",
    "print (\"Row axis labels and column axis labels are:\")\n",
    "print(data_xls.axes)\n",
    "print (\"The data types of each column are:\")\n",
    "print(data_xls.dtypes)\n",
    "print (\"The shape of the object is: r x c\")\n",
    "print(data_xls.shape)\n",
    "print(data_xls.describe())  #numerically describe columns in dataset\n",
    "\n",
    "#Visually Graph & discover in another tool such as tableau - export transformed/cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas File I/O Example - CSV Read\n",
      "        ID  Branch Interview Date Transaction Date Comment Type  \\\n",
      "0  4278642     355      2/24/2015        2/23/2015   Compliment   \n",
      "1  3329834     311      4/10/2014         4/9/2014   Compliment   \n",
      "2  4182303     353      1/14/2015        1/13/2015   Compliment   \n",
      "3  4228554     318       2/4/2015         2/3/2015   Compliment   \n",
      "4  3860433     351       9/4/2014         9/3/2014   Compliment   \n",
      "\n",
      "                                             Comment Follow-up  \\\n",
      "0  MY BANK is always good to me. I have banked wi...       NaN   \n",
      "1  MY BANK is the best for me. They help people w...       NaN   \n",
      "2  MY BANK has been 100 percent on top on any ban...       NaN   \n",
      "3  Absolutely no problems with them. Everything h...       NaN   \n",
      "4  Absolutely. They are efficient, courteous and ...       NaN   \n",
      "\n",
      "   Satisfaction Rating  \n",
      "0                   10  \n",
      "1                    8  \n",
      "2                    8  \n",
      "3                    9  \n",
      "4                    9  \n",
      "Row axis labels and column axis labels are:\n",
      "[RangeIndex(start=0, stop=1193, step=1), Index(['ID', 'Branch', 'Interview Date', 'Transaction Date', 'Comment Type',\n",
      "       'Comment', 'Follow-up', 'Satisfaction Rating'],\n",
      "      dtype='object')]\n",
      "The data types of each column are:\n",
      "ID                      int64\n",
      "Branch                  int64\n",
      "Interview Date         object\n",
      "Transaction Date       object\n",
      "Comment Type           object\n",
      "Comment                object\n",
      "Follow-up              object\n",
      "Satisfaction Rating     int64\n",
      "dtype: object\n",
      "The shape of the object is: r x c\n",
      "(1193, 8)\n",
      "                 ID       Branch  Satisfaction Rating\n",
      "count  1.193000e+03  1193.000000          1193.000000\n",
      "mean   4.297436e+06   295.588433             7.985750\n",
      "std    4.774175e+05    86.540331             2.252656\n",
      "min    3.276177e+06   107.000000             1.000000\n",
      "25%    3.954094e+06   310.000000             8.000000\n",
      "50%    4.322839e+06   320.000000             9.000000\n",
      "75%    4.720735e+06   352.000000             9.000000\n",
      "max    5.081369e+06   401.000000            10.000000\n",
      "0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "5       False\n",
      "6       False\n",
      "7       False\n",
      "8       False\n",
      "9       False\n",
      "10      False\n",
      "11      False\n",
      "12      False\n",
      "13      False\n",
      "14      False\n",
      "15      False\n",
      "16      False\n",
      "17      False\n",
      "18      False\n",
      "19      False\n",
      "20      False\n",
      "21      False\n",
      "22      False\n",
      "23      False\n",
      "24      False\n",
      "25      False\n",
      "26      False\n",
      "27      False\n",
      "28      False\n",
      "29      False\n",
      "        ...  \n",
      "1163    False\n",
      "1164    False\n",
      "1165    False\n",
      "1166    False\n",
      "1167    False\n",
      "1168    False\n",
      "1169    False\n",
      "1170    False\n",
      "1171    False\n",
      "1172    False\n",
      "1173    False\n",
      "1174    False\n",
      "1175    False\n",
      "1176    False\n",
      "1177    False\n",
      "1178    False\n",
      "1179    False\n",
      "1180    False\n",
      "1181    False\n",
      "1182    False\n",
      "1183    False\n",
      "1184    False\n",
      "1185    False\n",
      "1186    False\n",
      "1187    False\n",
      "1188    False\n",
      "1189    False\n",
      "1190    False\n",
      "1191    False\n",
      "1192    False\n",
      "Name: Comment, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#CRISP-DM Step 2b & 2c - transform data to place in Pandas dataset (Step 2a), \n",
    "#for further understanding and model prep/usage (Step 2b)\n",
    "#Pandas CSV Example - Step 2b\n",
    "data_csv = file_read_csv('C:\\\\Python\\\\Data\\\\Text_Mining_Sample_CSV.csv') #pandas read_csv function automatically returns a dataframe!\n",
    "print(data_csv.head())\n",
    "\n",
    "#Step 2c - Evaluate csv data for furter text (or other) analysis\n",
    "print (\"Row axis labels and column axis labels are:\")\n",
    "print(data_csv.axes)\n",
    "print (\"The data types of each column are:\")\n",
    "print(data_csv.dtypes)\n",
    "print (\"The shape of the object is: r x c\")\n",
    "print(data_csv.shape)\n",
    "print(data_csv.describe())  #numerically describe columns in dataset\n",
    "print(data_csv['Comment'].isnull()) #Check for missing values'\n",
    "\n",
    "#Visually Graph & discover in another tool such as tableau - export transformed/cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send Data to uclassify API, for model build & evaluation\n",
    "#request format:   \n",
    "#curl -X POST -H \"Authorization:Token YOUR_READ_API_KEY_HERE\" -H \"Content-Type: application/json\" --data \"{insert here}\" \n",
    "def API_put_uclassify(data):\n",
    "    api_key = 'uMxNaxJ9eYVL'\n",
    "    headers = {'Content-type': 'application/json', 'Authorization': 'Token ' + api_key}\n",
    "    view_url = 'https://api.uclassify.com/v1/uclassify/sentiment/classify'\n",
    "    print('API Put - convert dict data structure to json') \n",
    "    json2 = json.dumps(data) \n",
    "    #print(json2)\n",
    "    myResponse = requests.post(view_url, data=json2, headers=headers)\n",
    "    print (myResponse.status_code)\n",
    "    # For successful API call, response code will be 200 (OK)\n",
    "    if(myResponse.status_code == 200):\n",
    "        print(\"The API Put Request Was Successful\")\n",
    "        return myResponse\n",
    "    else:\n",
    "        #If response code is not ok (200), print the resulting http error code with description\n",
    "        print(\"The API Put Request Was Not Successful\")\n",
    "        return myResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Content-type': 'application/json', 'Authorization': 'Token uMxNaxJ9eYVL'}\n"
     ]
    }
   ],
   "source": [
    "api_key = 'uMxNaxJ9eYVL'\n",
    "headers = {'Content-type': 'application/json', 'Authorization': 'Token ' + api_key}\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Put - convert dict data structure to json\n",
      "200\n",
      "The API Put Request Was Successful\n",
      "{'textCoverage': 0.938696, 'classification': [{'className': 'negative', 'p': 0.787717}, {'className': 'positive', 'p': 0.212283}]}\n",
      "API Put - convert dict data structure to json\n",
      "200\n",
      "The API Put Request Was Successful\n",
      "{'textCoverage': 0.950031, 'classification': [{'className': 'negative', 'p': 0.784199}, {'className': 'positive', 'p': 0.215801}]}\n",
      "API Put - convert dict data structure to json\n",
      "200\n",
      "The API Put Request Was Successful\n",
      "{'textCoverage': 0.948675, 'classification': [{'className': 'negative', 'p': 0.790501}, {'className': 'positive', 'p': 0.209499}]}\n"
     ]
    }
   ],
   "source": [
    "#step 3a) Build Model, then 3b) test & evaluate\n",
    "#note - for UClassify, split into test/train dataset, then compare results\n",
    "#in general - will build a model using data science libraries such as Scikit-Learn, then use corresponding test statistics\n",
    "#first, get text-only data from set(s) obtained in CRISP-DM step 2 - Convert to Dict Structure\n",
    "text_dict = data_csv['Comment'].to_dict()\n",
    "#print(text_dict[0])\n",
    "uclassify_text_all = \"\"\n",
    "uclassify_text_test1 = \"\"\n",
    "uclassify_text_test2 = \"\"\n",
    "#step 3b) split pandas dataset into test/train, to evaluate model quality on dataset \n",
    "for key in text_dict:\n",
    "    uclassify_text_all += text_dict[key]\n",
    "    if random() < .5:\n",
    "        uclassify_text_test1 += text_dict[key]\n",
    "    else:\n",
    "        uclassify_text_test2 += text_dict[key]\n",
    "\n",
    "#preprocess text (if wanted/required), then place in dictioary for conversion to json in api call\n",
    "uclassify_dict_all = {}\n",
    "uclassify_dict_all[\"texts\"]=[uclassify_text_all]\n",
    "\n",
    "uclassify_dict_test1 = {}\n",
    "uclassify_dict_test1[\"texts\"]=[uclassify_text_test1]\n",
    "\n",
    "uclassify_dict_test2 = {}\n",
    "uclassify_dict_test2[\"texts\"]=[uclassify_text_test2]\n",
    "\n",
    "#print(json.dumps(uclassify_dict))  <-- how to convert diction to json data structure\n",
    "#print(uclassify_dict_all)\n",
    "#print(uclassify_dict_test1)\n",
    "#print(uclassify_dict_test2)\n",
    "\n",
    "#step 3a/b) u-classify models are pre-trained/built, so call rest api to run model on data \n",
    "json1 = API_put_uclassify(uclassify_dict_all)\n",
    "json_all = json.loads(json1.text)[0] #returs dictionary\n",
    "print(json_all) #returned json response\n",
    "\n",
    "json2 = API_put_uclassify(uclassify_dict_test1)\n",
    "json_test1= json.loads(json2.text)[0] #returs dictionary\n",
    "print(json_test1) #returned json response\n",
    "\n",
    "json3 = API_put_uclassify(uclassify_dict_test2) \n",
    "json_test2= json.loads(json3.text)[0] #returs dictionary\n",
    "print(json_test2) #returned json responsey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sentiment', 'All', 1, 0.938696, 0.787717, 0.212283]\n",
      "['Sentiment', 'Test1', 1, 0.950031, 0.784199, 0.215801]\n",
      "['Sentiment', 'Test2', 1, 0.948675, 0.790501, 0.209499]\n"
     ]
    }
   ],
   "source": [
    "#step 6a) Store results of model build, for evaluation purposes\n",
    "#create list, using [classifier, trial_name, text_coverage, negative_p, positive_p] convention\n",
    "trial_all = ['Sentiment', 'All', 1, json_all['textCoverage'], json_all['classification'][0]['p'], json_all['classification'][1]['p']]\n",
    "print(trial_all) #returned json response\n",
    "trial_test1 = ['Sentiment', 'Test1', 1, json_test1['textCoverage'], json_test1['classification'][0]['p'], json_test1['classification'][1]['p']]\n",
    "print(trial_test1) #returned json response\n",
    "trial_test2 = ['Sentiment', 'Test2', 1, json_test2['textCoverage'], json_test2['classification'][0]['p'], json_test2['classification'][1]['p']]\n",
    "print(trial_test2) #returned json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API Get Request Was Successful\n",
      "\n",
      "\n",
      "200\n",
      "The API Post Request Was Successful\n",
      "200\n",
      "The API Post Request Was Successful\n",
      "200\n",
      "The API Post Request Was Successful\n"
     ]
    }
   ],
   "source": [
    "#step 6b) export results of analysis to google fusion table, for use in data products\n",
    "#Step 1 - Identify Resource: set url for json request\n",
    "view_url = 'https://accounts.google.com/o/oauth2/token'\n",
    "#Step 2 & 3 - Identify Endpoints, Methods and Set request parameters\n",
    "client_id='615800458288-5fktbjo6kmu18bpgl18glnj2l12mvg8i.apps.googleusercontent.com'\n",
    "client_secret='QowLGwV4wueqHpV_t1sotQVh'\n",
    "refresh_token = '1/vz7AvnbcT05ZJI-SQcFACqhaif9hXCfeuTM8n1DI12E'\n",
    "refresh_body = \"refresh_token=\" + refresh_token + '&client_id=' + client_id + '&client_secret=' + client_secret + '&grant_type=refresh_token'\n",
    "\n",
    "#Step 1-3) Google Fusion Tables OAuth keys\n",
    "def API_POST_OAuth():\n",
    "    #set url for json request, then obtain json response/payload\n",
    "    headers = {'Content-type': 'application/x-www-form-urlencoded', 'Accept': 'text/plain'}\n",
    "    myResponse = requests.post(view_url, data=refresh_body, headers=headers)\n",
    "    # For successful API call, response code will be 200 (OK)\n",
    "    if(myResponse.ok):\n",
    "        # Loads (Load String) takes a Json file and converts into python data structure \n",
    "        # (dict or list, depending on JSON structure and number of records returned\n",
    "        jData = myResponse.content \n",
    "        # Loading the response data into a dict variable\n",
    "        jData = json.loads(jData) \n",
    "        print(\"The API Get Request Was Successful\")\n",
    "        print(\"\\n\")\n",
    "        return jData\n",
    "        \n",
    "    else:\n",
    "        # If response code is not ok (200), print the resulting http error code with description\n",
    "        print('API Error')\n",
    "        return ''\n",
    "\n",
    "#Step 1-3) Google Fusion Table - Replace\n",
    "def API_POST_Data(access_token, table_id, data):\n",
    "    data_view_url = \"https://www.googleapis.com/upload/fusiontables/v2/tables/\" + table_id + '/import?&access_token=' + access_token + '&isStrict=false'\n",
    "    headers = {'Content-type': 'application/octet-stream'}\n",
    "    #create post response body - comma seperated string of all obs\n",
    "    data2 = data[0] + ', ' + data[1] + ', ' + str(data[2]) + ', ' + str(data[3]) + ', ' + str(data[4]) + ', ' + str(data[5]) +'\\n'\n",
    "    myResponse = requests.post(data_view_url, data=data2, headers=headers)\n",
    "    print (myResponse.status_code)\n",
    "    # For successful API call, response code will be 200 (OK)\n",
    "    if(myResponse.status_code == 200):\n",
    "        return \"The API Post Request Was Successful\"\n",
    "    else:\n",
    "        #If response code is not ok (200), print the resulting http error code with description\n",
    "        return \"The API Post Request Was Not Successful\"\n",
    "\n",
    "#step 4 - create request data structure from csv file, to replace data in the \"OSDA Stock History\" google fusion table\n",
    "#https://fusiontables.google.com/data?docid=1a8EPfomscPkMYksFrlGoyU4utoT0QdLCpH9tySDP#rows:id=1 \n",
    "#Obtain Google Fusion OAuth token \n",
    "data = API_POST_OAuth()\n",
    "access_token = data['access_token']\n",
    "\n",
    "#Put data in google fusion table\n",
    "table_id = '1tTpKKRw9Fvo0fh2Pw7v2R8L9fgPOlK2bq7KMaS70'\n",
    "#convert list results from model to dictionary - data = {trial_all, trial_test1, trial_test2}\n",
    "status = API_POST_Data(access_token, table_id, trial_all)  #\"put\" data using API class\n",
    "print(status)\n",
    "status = API_POST_Data(access_token, table_id, trial_test1)  #\"put\" data using API class\n",
    "print(status)\n",
    "status = API_POST_Data(access_token, table_id, trial_test2)  #\"put\" data using API class\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
